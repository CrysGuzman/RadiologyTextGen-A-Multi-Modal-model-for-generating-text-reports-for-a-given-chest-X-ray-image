{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a057c6d3-5295-4a35-8a9d-972442cd77cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 04:35:33.376401: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-09 04:35:33.416041: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ada92c6-fb2a-4cbc-b7b5-743fabac8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf795a43-f3e5-4953-876d-5b98e28e4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1771\n"
     ]
    }
   ],
   "source": [
    "# File path where the sentences are saved\n",
    "file_path = 'unique_sentences.txt'\n",
    "\n",
    "# Initialize an empty list to store the sentences\n",
    "sentences = []\n",
    "\n",
    "# Open the file and read each line\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Strip newline characters and add to the list\n",
    "        sentences.append(line.strip())\n",
    "\n",
    "# Now 'sentences' contains all the sentences from the file\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeec1c2f-3af9-4c59-9d07-7bfe82e83cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vocab_size(sentences):\n",
    "    # Tokenize each sentence into words and normalize them to lowercase\n",
    "    words = [word.lower() for sentence in sentences for word in sentence.split()]\n",
    "\n",
    "    # Create a set of unique words\n",
    "    unique_words = set(words)\n",
    "\n",
    "    # Return the size of the unique word set (VocabSize)\n",
    "    return len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f781a4-7eaa-43af-8696-3235f819ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2161"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = calculate_vocab_size(sentences)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59906d7b-53e9-40c6-955b-1fb3690f9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3d895a-0916-4c2f-823c-48be96111ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentences and obtain embeddings\n",
    "embeddings = []\n",
    "for sentence in sentences_list:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "\n",
    "# Save embeddings to a pickle file\n",
    "with open('uniqueSentences_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dafcbf1-99dd-475d-b0ea-0602ecdec3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7470"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2e83cb-d907-4833-9bb1-1e81c19e867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Value: -10.043437004089355\n",
      "Maximum Value: 1.5820293426513672\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming `embeddings` is a list of numpy arrays\n",
    "# Flatten all embeddings into a single array\n",
    "all_embeddings = np.concatenate(embeddings)\n",
    "\n",
    "# Find the minimum and maximum values\n",
    "min_value = np.min(all_embeddings)\n",
    "max_value = np.max(all_embeddings)\n",
    "\n",
    "print(f\"Minimum Value: {min_value}\")\n",
    "print(f\"Maximum Value: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcd632-812b-4b29-aa0d-c091652b9129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
