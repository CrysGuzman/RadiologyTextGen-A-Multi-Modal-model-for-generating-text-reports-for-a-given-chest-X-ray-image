{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9fef42-3558-4362-9de5-8d619abeb7e4",
   "metadata": {},
   "source": [
    "#### This code develops and trains a model to take text embeddings as input and generates the impression sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52443e74-cc7f-42d6-b1b3-b22066fca3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 04:37:42.074673: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-09 04:37:42.123854: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-09 04:37:44.015089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.038044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.038092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.045068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.045118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.045144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.940466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.940520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.940527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-09 04:37:44.940551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-09 04:37:44.940580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45461 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:4b:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 768)]                0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 768, 1)               0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            1024256   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 256),                264192    ['reshape[0][0]']             \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 256),          525312    ['embedding[0][0]',           \n",
      "                              (None, 256),                           'lstm[0][1]',                \n",
      "                              (None, 256)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 4001)           1028257   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2842017 (10.84 MB)\n",
      "Trainable params: 2842017 (10.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Reshape\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 768  # Dimension of your sentence embeddings\n",
    "lstm_units = 256     # Number of units in LSTM\n",
    "# Assuming your vocabulary size and maximum sentence length\n",
    "vocab_size = 4001\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(embedding_dim,))  # Your embeddings size\n",
    "\n",
    "# Reshape input to add a time dimension (e.g., treating each feature as a time step)\n",
    "encoder_reshaped = Reshape((embedding_dim, 1))(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_reshaped)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=256)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "embedded_decoder_inputs = decoder_embedding(decoder_inputs)\n",
    "decoder_outputs, _, _ = decoder_lstm(embedded_decoder_inputs, initial_state=encoder_states)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Summary\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "# You need to prepare your data accordingly\n",
    "# model.fit([input_embeddings, decoder_input_data], decoder_target_data, batch_size=64, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1846980f-cecc-438b-a700-8653d7818ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 768)]                0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 768, 1)               0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            553216    ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 256),                264192    ['reshape_1[0][0]']           \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, None, 256),          525312    ['embedding_1[0][0]',         \n",
      "                              (None, 256),                           'lstm_2[0][1]',              \n",
      "                              (None, 256)]                           'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 256)            0         ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 2161)           555377    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1898097 (7.24 MB)\n",
      "Trainable params: 1898097 (7.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Reshape, Dropout\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "\n",
    "# Parameters\n",
    "embedding_dim = 768\n",
    "lstm_units = 256\n",
    "vocab_size = 2161\n",
    "dropout_rate = 0.2  # Dropout rate\n",
    "l2_reg = 1e-4       # L2 regularization factor\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(embedding_dim,))\n",
    "encoder_reshaped = Reshape((embedding_dim, 1))(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True, dropout=dropout_rate, \n",
    "                    recurrent_regularizer=L1L2(l2=l2_reg))  # Apply L2 regularization here\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_reshaped)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=256)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True, dropout=dropout_rate, \n",
    "                    recurrent_regularizer=L1L2(l2=l2_reg))  # Apply L2 regularization here\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "\n",
    "embedded_decoder_inputs = decoder_embedding(decoder_inputs)\n",
    "decoder_outputs, _, _ = decoder_lstm(embedded_decoder_inputs, initial_state=encoder_states)\n",
    "decoder_outputs = Dropout(dropout_rate)(decoder_outputs)  # Dropout after LSTM\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Training with early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# You need to prepare your data accordingly\n",
    "# model.fit([input_embeddings, decoder_input_data], decoder_target_data,\n",
    "#           batch_size=64, epochs=100, callbacks=[early_stopping], validation_data=(val_input, val_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd896463-3b99-4b3a-933b-eba7fc33756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the data from the pickle file\n",
    "with open('uniqueSentences_embeddings.pkl', 'rb') as fin:\n",
    "    data = pickle.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec05a2ec-633d-4b04-be7b-2f08e157e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da5e721-d042-4339-8792-24cd57bf812d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c6f053-e085-4894-a7b6-82f8ed379aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(embedding.shape[0] for embedding in text_embeddings)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee67869-6983-4784-a279-4dd1bca6850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to pad embeddings\n",
    "def pad_embeddings(embeddings, max_length):\n",
    "    padded_embeddings = []\n",
    "    for embedding in embeddings:\n",
    "        # Calculate padding length\n",
    "        padding_length = max_length - embedding.shape[0]\n",
    "        \n",
    "        # Create padding (zero padding in this example)\n",
    "        padding = np.zeros(padding_length)\n",
    "\n",
    "        # Append padding to the embedding\n",
    "        padded_embedding = np.append(embedding, padding)\n",
    "        padded_embeddings.append(padded_embedding)\n",
    "\n",
    "    return np.array(padded_embeddings)\n",
    "\n",
    "# Apply padding\n",
    "padded_embeddings = pad_embeddings(text_embeddings, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c0da93-ba52-4d76-8e62-aeda43a8a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unique_sentences.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "sentences_list = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d221e5aa-f1a4-434a-a0d1-12f844b515b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 2161  # Your vocabulary size\n",
    "max_sentence_length = 768  # Max length of the sentence\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences_list)\n",
    "target_sequences = tokenizer.texts_to_sequences(sentences_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0adead-4433-4e08-8725-236eb553fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "target_padded = pad_sequences(target_sequences, maxlen=max_sentence_length, padding='post')\n",
    "\n",
    "# One-hot Encoding\n",
    "#target_one_hot = np.array([to_categorical(seq, num_classes=vocab_size) for seq in target_padded])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7642da3c-e300-4d5a-97e7-dbb85f2ebb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, split your data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_val, target_train, target_val = train_test_split(padded_embeddings, target_padded, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebaa09c3-fd06-4a67-a6fa-75733266a438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1d52ee-511c-434c-b7d6-b9593ee34efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor for improvement (validation loss)\n",
    "    min_delta = 0.001, \n",
    "    patience=5,  # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True  # Restore the model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50e82295-4128-4929-934b-f15f600ffdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift target sequences by one for the decoder input\n",
    "decoder_input_data = np.zeros_like(target_padded)\n",
    "decoder_input_data[:, 1:] = target_padded[:, :-1]  # Shift target sequence\n",
    "\n",
    "# The decoder output data is the original target sequence\n",
    "decoder_target_data = target_padded\n",
    "\n",
    "# Split data into training and validation sets\n",
    "input_train, input_val, decoder_input_train, decoder_input_val, target_train, target_val = train_test_split(\n",
    "    padded_embeddings, decoder_input_data, target_padded, test_size=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be41e73-983c-46f7-82f0-65804102da60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 04:38:26.928679: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2023-12-09 04:38:27.317597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-12-09 04:38:27.380486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x36dd71f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-09 04:38:27.380538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9\n",
      "2023-12-09 04:38:27.421246: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-09 04:38:27.699459: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-09 04:38:27.818762: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 20s 154ms/step - loss: 0.9329 - val_loss: 0.2249\n",
      "Epoch 2/100\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 0.2204 - val_loss: 0.2115\n",
      "Epoch 3/100\n",
      "89/89 [==============================] - 6s 67ms/step - loss: 0.1999 - val_loss: 0.1719\n",
      "Epoch 4/100\n",
      "89/89 [==============================] - 5s 60ms/step - loss: 0.1591 - val_loss: 0.1480\n",
      "Epoch 5/100\n",
      "89/89 [==============================] - 5s 55ms/step - loss: 0.1479 - val_loss: 0.1426\n",
      "Epoch 6/100\n",
      "89/89 [==============================] - 5s 52ms/step - loss: 0.1424 - val_loss: 0.1379\n",
      "Epoch 7/100\n",
      "89/89 [==============================] - 5s 51ms/step - loss: 0.1371 - val_loss: 0.1324\n",
      "Epoch 8/100\n",
      "89/89 [==============================] - 4s 50ms/step - loss: 0.1307 - val_loss: 0.1253\n",
      "Epoch 9/100\n",
      "89/89 [==============================] - 4s 48ms/step - loss: 0.1225 - val_loss: 0.1165\n",
      "Epoch 10/100\n",
      "89/89 [==============================] - 4s 48ms/step - loss: 0.1136 - val_loss: 0.1077\n",
      "Epoch 11/100\n",
      "89/89 [==============================] - 4s 49ms/step - loss: 0.1046 - val_loss: 0.0990\n",
      "Epoch 12/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0963 - val_loss: 0.0910\n",
      "Epoch 13/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0884 - val_loss: 0.0835\n",
      "Epoch 14/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0805 - val_loss: 0.0758\n",
      "Epoch 15/100\n",
      "89/89 [==============================] - 4s 49ms/step - loss: 0.0730 - val_loss: 0.0685\n",
      "Epoch 16/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0658 - val_loss: 0.0620\n",
      "Epoch 17/100\n",
      "89/89 [==============================] - 4s 49ms/step - loss: 0.0592 - val_loss: 0.0562\n",
      "Epoch 18/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0534 - val_loss: 0.0512\n",
      "Epoch 19/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0483 - val_loss: 0.0468\n",
      "Epoch 20/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0436 - val_loss: 0.0428\n",
      "Epoch 21/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0394 - val_loss: 0.0392\n",
      "Epoch 22/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0356 - val_loss: 0.0361\n",
      "Epoch 23/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0322 - val_loss: 0.0333\n",
      "Epoch 24/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0292 - val_loss: 0.0308\n",
      "Epoch 25/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0265 - val_loss: 0.0286\n",
      "Epoch 26/100\n",
      "89/89 [==============================] - 4s 46ms/step - loss: 0.0241 - val_loss: 0.0266\n",
      "Epoch 27/100\n",
      "89/89 [==============================] - 4s 46ms/step - loss: 0.0220 - val_loss: 0.0250\n",
      "Epoch 28/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 29/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0183 - val_loss: 0.0221\n",
      "Epoch 30/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0168 - val_loss: 0.0209\n",
      "Epoch 31/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0155 - val_loss: 0.0199\n",
      "Epoch 32/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0142 - val_loss: 0.0189\n",
      "Epoch 33/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0131 - val_loss: 0.0181\n",
      "Epoch 34/100\n",
      "89/89 [==============================] - 4s 49ms/step - loss: 0.0121 - val_loss: 0.0173\n",
      "Epoch 35/100\n",
      "89/89 [==============================] - 4s 46ms/step - loss: 0.0111 - val_loss: 0.0166\n",
      "Epoch 36/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0102 - val_loss: 0.0159\n",
      "Epoch 37/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0095 - val_loss: 0.0153\n",
      "Epoch 38/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0087 - val_loss: 0.0148\n",
      "Epoch 39/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 40/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0075 - val_loss: 0.0139\n",
      "Epoch 41/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0069 - val_loss: 0.0134\n",
      "Epoch 42/100\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 0.0063 - val_loss: 0.0130\n",
      "Epoch 43/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0058 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0054 - val_loss: 0.0123\n",
      "Epoch 45/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 46/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0041 - val_loss: 0.0113\n",
      "Epoch 48/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0038 - val_loss: 0.0110\n",
      "Epoch 49/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0035 - val_loss: 0.0107\n",
      "Epoch 50/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0032 - val_loss: 0.0104\n",
      "Epoch 51/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0029 - val_loss: 0.0102\n",
      "Epoch 52/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0026 - val_loss: 0.0099\n",
      "Epoch 53/100\n",
      "89/89 [==============================] - 4s 46ms/step - loss: 0.0024 - val_loss: 0.0097\n",
      "Epoch 54/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0021 - val_loss: 0.0094\n",
      "Epoch 55/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0019 - val_loss: 0.0092\n",
      "Epoch 56/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0017 - val_loss: 0.0090\n",
      "Epoch 57/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0015 - val_loss: 0.0088\n",
      "Epoch 58/100\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 59/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0012 - val_loss: 0.0084\n",
      "Epoch 60/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 0.0011 - val_loss: 0.0082\n",
      "Epoch 61/100\n",
      "89/89 [==============================] - 4s 44ms/step - loss: 9.4875e-04 - val_loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f429476a610>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit([input_train, target_train], target_train,\n",
    "          batch_size=16,\n",
    "          epochs=100,\n",
    "          validation_data=([input_val, target_val], target_val),\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e62b4-824c-4e1d-95d0-7a671cfedf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6837316d-4de1-4696-9a9b-fd4bac156304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('tokenizer3.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39b9b6bb-ef66-4047-95de-e58d6a0ed05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoha108/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model4_unique3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fbe9f-769c-4401-8a54-1c9f04f94f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
