{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4278781",
   "metadata": {},
   "source": [
    "##### Here, we develop a model that takes the image embeddings as input and predicts the text embeddings. A CNN network was developed and finalized after several experiments with different set of NN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7eafce8-9a8d-4e6f-9e73-3ec9e08ce49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 19:40:38.005858: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-14 19:40:38.318503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293288e1-75a7-4d8e-b847-88126a57f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def masked_mae_loss(y_true, y_pred):\n",
    "    # Create a mask for non-padded elements (Assuming padding is done with zeros)\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error loss\n",
    "    loss = tf.abs(y_true - y_pred)\n",
    "\n",
    "    # Apply the mask to ignore padded elements\n",
    "    loss *= mask\n",
    "\n",
    "    # Calculate the mean loss considering only the non-padded elements\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b41b4b-d03a-457e-b1e5-f180229326b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bb8d6e-d69b-4214-a68d-85bf00cd5ba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 19:40:41.585020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:41.765406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:41.765457: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:41.772342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:41.772390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:41.772413: I tensorflow/compile"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 512)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 512)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 256)       1179904   \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 128)         295040    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 64)          73792     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              66560     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 768)               197376    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4828608 (18.42 MB)\n",
      "Trainable params: 4828608 (18.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:42.874068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:42.874133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:42.874141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-11-14 19:40:42.874170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:4b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-14 19:40:42.874203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45461 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:4b:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (28, 28, 512)  # As per your image embeddings\n",
    "\n",
    "# Model architecture\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Convolutional layer\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "# Flatten the output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Dense layers with Dropout\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(768, activation='linear')(x)  # Linear activation for regression\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89498a5-978f-4608-a32f-12501f1eed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor for improvement (validation loss)\n",
    "    patience=35,  # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True  # Restore the model weights from the epoch with the best value of the monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5432fb21-fef3-42ca-8f5f-313a5fe5f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "image_features = np.load('imgEmbeddingsB4C4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16fbe5c-0838-4f9c-8e00-4a952757c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features[np.isnan(image_features)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02f149c-27cc-4dbc-a355-e1f4ab12c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the data from the pickle file\n",
    "with open('text_embeddings.pkl', 'rb') as fin:\n",
    "    data = pickle.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5feb8ab4-4d3f-4737-8ed7-d787a3bfa8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edad0e0a-6107-4cc7-9dfc-79619fe176ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(embedding.shape[0] for embedding in text_embeddings)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd287aeb-ff46-4923-8253-6a832ab18c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad embeddings\n",
    "def pad_embeddings(embeddings, max_length):\n",
    "    padded_embeddings = []\n",
    "    for embedding in embeddings:\n",
    "        # Calculate padding length\n",
    "        padding_length = max_length - embedding.shape[0]\n",
    "        \n",
    "        # Create padding (zero padding in this example)\n",
    "        padding = np.zeros(padding_length)\n",
    "\n",
    "        # Append padding to the embedding\n",
    "        padded_embedding = np.append(embedding, padding)\n",
    "        padded_embeddings.append(padded_embedding)\n",
    "\n",
    "    return np.array(padded_embeddings)\n",
    "\n",
    "# Apply padding\n",
    "padded_embeddings = pad_embeddings(text_embeddings, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e2cff0-bab9-4323-a8e8-d54fa0be1c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7470, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cbd2bbd-7d43-4ed8-a348-a5c935e9ba61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 19:41:47.790563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2023-11-14 19:41:49.604666: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-14 19:41:49.946307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-14 19:41:49.971025: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec47880800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-14 19:41:49.971066: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX 6000 Ada Generation, Compute Capability 8.9\n",
      "2023-11-14 19:41:50.013056: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-14 19:41:50.300762: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-14 19:41:50.386900: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 15s 35ms/step - loss: 0.1818 - val_loss: 0.1220\n",
      "Epoch 2/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1268 - val_loss: 0.1179\n",
      "Epoch 3/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1226 - val_loss: 0.1162\n",
      "Epoch 4/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1180 - val_loss: 0.1088\n",
      "Epoch 5/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1124 - val_loss: 0.1084\n",
      "Epoch 6/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1151 - val_loss: 0.1086\n",
      "Epoch 7/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1118 - val_loss: 0.1086\n",
      "Epoch 8/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1114 - val_loss: 0.1082\n",
      "Epoch 9/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1114 - val_loss: 0.1084\n",
      "Epoch 10/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1122 - val_loss: 0.1084\n",
      "Epoch 11/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1206 - val_loss: 0.1085\n",
      "Epoch 12/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1120 - val_loss: 0.1085\n",
      "Epoch 13/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1113 - val_loss: 0.1082\n",
      "Epoch 14/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1112 - val_loss: 0.1083\n",
      "Epoch 15/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1112 - val_loss: 0.1091\n",
      "Epoch 16/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1113 - val_loss: 0.1084\n",
      "Epoch 17/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1124 - val_loss: 0.1085\n",
      "Epoch 18/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1111 - val_loss: 0.1084\n",
      "Epoch 19/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1111 - val_loss: 0.1084\n",
      "Epoch 20/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1110 - val_loss: 0.1085\n",
      "Epoch 21/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1110 - val_loss: 0.1083\n",
      "Epoch 22/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1110 - val_loss: 0.1082\n",
      "Epoch 23/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1081\n",
      "Epoch 24/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1082\n",
      "Epoch 25/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1084\n",
      "Epoch 26/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1137 - val_loss: 0.1084\n",
      "Epoch 27/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1113 - val_loss: 0.1084\n",
      "Epoch 28/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1082\n",
      "Epoch 29/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1084\n",
      "Epoch 30/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1084\n",
      "Epoch 31/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1109 - val_loss: 0.1083\n",
      "Epoch 32/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1108 - val_loss: 0.1089\n",
      "Epoch 33/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1108 - val_loss: 0.1085\n",
      "Epoch 34/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1108 - val_loss: 0.1082\n",
      "Epoch 35/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1108 - val_loss: 0.1083\n",
      "Epoch 36/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1107 - val_loss: 0.1083\n",
      "Epoch 37/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1116 - val_loss: 0.1086\n",
      "Epoch 38/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1295 - val_loss: 0.1083\n",
      "Epoch 39/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1119 - val_loss: 0.1083\n",
      "Epoch 40/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1110 - val_loss: 0.1082\n",
      "Epoch 41/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1110 - val_loss: 0.1082\n",
      "Epoch 42/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1108 - val_loss: 0.1084\n",
      "Epoch 43/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1107 - val_loss: 0.1082\n",
      "Epoch 44/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1107 - val_loss: 0.1083\n",
      "Epoch 45/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1107 - val_loss: 0.1082\n",
      "Epoch 46/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1107 - val_loss: 0.1083\n",
      "Epoch 47/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1107 - val_loss: 0.1082\n",
      "Epoch 48/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1107 - val_loss: 0.1083\n",
      "Epoch 49/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1106 - val_loss: 0.1083\n",
      "Epoch 50/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1106 - val_loss: 0.1082\n",
      "Epoch 51/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1106 - val_loss: 0.1082\n",
      "Epoch 52/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1106 - val_loss: 0.1083\n",
      "Epoch 53/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1106 - val_loss: 0.1082\n",
      "Epoch 54/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1105 - val_loss: 0.1085\n",
      "Epoch 55/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1105 - val_loss: 0.1083\n",
      "Epoch 56/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1105 - val_loss: 0.1082\n",
      "Epoch 57/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1103 - val_loss: 0.1083\n",
      "Epoch 58/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1101 - val_loss: 0.1082\n",
      "Epoch 59/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1097 - val_loss: 0.1085\n",
      "Epoch 60/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1107 - val_loss: 0.1087\n",
      "Epoch 61/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1215 - val_loss: 0.1084\n",
      "Epoch 62/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1092 - val_loss: 0.1083\n",
      "Epoch 63/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1081 - val_loss: 0.1084\n",
      "Epoch 64/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1072 - val_loss: 0.1082\n",
      "Epoch 65/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1068 - val_loss: 0.1088\n",
      "Epoch 66/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1066 - val_loss: 0.1084\n",
      "Epoch 67/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1065 - val_loss: 0.1085\n",
      "Epoch 68/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1064 - val_loss: 0.1082\n",
      "Epoch 69/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1062 - val_loss: 0.1089\n",
      "Epoch 70/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1063 - val_loss: 0.1082\n",
      "Epoch 71/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1062 - val_loss: 0.1082\n",
      "Epoch 72/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1060 - val_loss: 0.1086\n",
      "Epoch 73/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1060 - val_loss: 0.1082\n",
      "Epoch 74/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1076 - val_loss: 0.1082\n",
      "Epoch 75/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1064 - val_loss: 0.1082\n",
      "Epoch 76/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1059 - val_loss: 0.1081\n",
      "Epoch 77/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1056 - val_loss: 0.1082\n",
      "Epoch 78/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1055 - val_loss: 0.1084\n",
      "Epoch 79/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1054 - val_loss: 0.1084\n",
      "Epoch 80/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1053 - val_loss: 0.1082\n",
      "Epoch 81/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1053 - val_loss: 0.1087\n",
      "Epoch 82/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1051 - val_loss: 0.1083\n",
      "Epoch 83/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1051 - val_loss: 0.1085\n",
      "Epoch 84/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1050 - val_loss: 0.1085\n",
      "Epoch 85/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1049 - val_loss: 0.1082\n",
      "Epoch 86/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1048 - val_loss: 0.1084\n",
      "Epoch 87/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1048 - val_loss: 0.1084\n",
      "Epoch 88/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1048 - val_loss: 0.1084\n",
      "Epoch 89/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1047 - val_loss: 0.1082\n",
      "Epoch 90/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1046 - val_loss: 0.1083\n",
      "Epoch 91/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1045 - val_loss: 0.1082\n",
      "Epoch 92/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1044 - val_loss: 0.1082\n",
      "Epoch 93/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1047 - val_loss: 0.1086\n",
      "Epoch 94/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1043 - val_loss: 0.1082\n",
      "Epoch 95/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1043 - val_loss: 0.1086\n",
      "Epoch 96/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1044 - val_loss: 0.1083\n",
      "Epoch 97/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1041 - val_loss: 0.1084\n",
      "Epoch 98/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1041 - val_loss: 0.1082\n",
      "Epoch 99/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1039 - val_loss: 0.1082\n",
      "Epoch 100/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1039 - val_loss: 0.1085\n",
      "Epoch 101/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1037 - val_loss: 0.1081\n",
      "Epoch 102/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1037 - val_loss: 0.1082\n",
      "Epoch 103/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1037 - val_loss: 0.1082\n",
      "Epoch 104/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1035 - val_loss: 0.1082\n",
      "Epoch 105/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1034 - val_loss: 0.1082\n",
      "Epoch 106/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1087 - val_loss: 0.1082\n",
      "Epoch 107/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1046 - val_loss: 0.1086\n",
      "Epoch 108/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1040 - val_loss: 0.1084\n",
      "Epoch 109/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1045 - val_loss: 0.1081\n",
      "Epoch 110/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1035 - val_loss: 0.1082\n",
      "Epoch 111/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1032 - val_loss: 0.1082\n",
      "Epoch 112/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1030 - val_loss: 0.1083\n",
      "Epoch 113/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1029 - val_loss: 0.1082\n",
      "Epoch 114/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1028 - val_loss: 0.1083\n",
      "Epoch 115/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1028 - val_loss: 0.1081\n",
      "Epoch 116/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1029 - val_loss: 0.1081\n",
      "Epoch 117/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1028 - val_loss: 0.1084\n",
      "Epoch 118/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1027 - val_loss: 0.1083\n",
      "Epoch 119/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1029 - val_loss: 0.1083\n",
      "Epoch 120/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1032 - val_loss: 0.1082\n",
      "Epoch 121/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1030 - val_loss: 0.1085\n",
      "Epoch 122/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1027 - val_loss: 0.1081\n",
      "Epoch 123/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1025 - val_loss: 0.1081\n",
      "Epoch 124/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1023 - val_loss: 0.1083\n",
      "Epoch 125/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1023 - val_loss: 0.1084\n",
      "Epoch 126/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1022 - val_loss: 0.1085\n",
      "Epoch 127/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1022 - val_loss: 0.1082\n",
      "Epoch 128/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1023 - val_loss: 0.1082\n",
      "Epoch 129/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1022 - val_loss: 0.1082\n",
      "Epoch 130/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1019 - val_loss: 0.1082\n",
      "Epoch 131/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1017 - val_loss: 0.1082\n",
      "Epoch 132/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1017 - val_loss: 0.1084\n",
      "Epoch 133/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1017 - val_loss: 0.1083\n",
      "Epoch 134/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1015 - val_loss: 0.1081\n",
      "Epoch 135/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1017 - val_loss: 0.1081\n",
      "Epoch 136/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1045 - val_loss: 0.1084\n",
      "Epoch 137/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1020 - val_loss: 0.1082\n",
      "Epoch 138/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1013 - val_loss: 0.1081\n",
      "Epoch 139/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1020 - val_loss: 0.1084\n",
      "Epoch 140/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1015 - val_loss: 0.1083\n",
      "Epoch 141/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1010 - val_loss: 0.1081\n",
      "Epoch 142/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1006 - val_loss: 0.1082\n",
      "Epoch 143/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1005 - val_loss: 0.1084\n",
      "Epoch 144/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1004 - val_loss: 0.1081\n",
      "Epoch 145/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1002 - val_loss: 0.1084\n",
      "Epoch 146/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.1002 - val_loss: 0.1081\n",
      "Epoch 147/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1001 - val_loss: 0.1082\n",
      "Epoch 148/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0999 - val_loss: 0.1083\n",
      "Epoch 149/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0998 - val_loss: 0.1081\n",
      "Epoch 150/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0998 - val_loss: 0.1081\n",
      "Epoch 151/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0997 - val_loss: 0.1081\n",
      "Epoch 152/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0996 - val_loss: 0.1082\n",
      "Epoch 153/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0995 - val_loss: 0.1081\n",
      "Epoch 154/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0993 - val_loss: 0.1082\n",
      "Epoch 155/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0992 - val_loss: 0.1081\n",
      "Epoch 156/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0991 - val_loss: 0.1081\n",
      "Epoch 157/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0989 - val_loss: 0.1081\n",
      "Epoch 158/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0988 - val_loss: 0.1082\n",
      "Epoch 159/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0987 - val_loss: 0.1083\n",
      "Epoch 160/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0987 - val_loss: 0.1084\n",
      "Epoch 161/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0986 - val_loss: 0.1083\n",
      "Epoch 162/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0985 - val_loss: 0.1083\n",
      "Epoch 163/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0984 - val_loss: 0.1081\n",
      "Epoch 164/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0982 - val_loss: 0.1081\n",
      "Epoch 165/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0992 - val_loss: 0.1083\n",
      "Epoch 166/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0986 - val_loss: 0.1082\n",
      "Epoch 167/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0985 - val_loss: 0.1085\n",
      "Epoch 168/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0984 - val_loss: 0.1082\n",
      "Epoch 169/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0979 - val_loss: 0.1082\n",
      "Epoch 170/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0977 - val_loss: 0.1083\n",
      "Epoch 171/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0976 - val_loss: 0.1083\n",
      "Epoch 172/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0975 - val_loss: 0.1082\n",
      "Epoch 173/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0974 - val_loss: 0.1082\n",
      "Epoch 174/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0974 - val_loss: 0.1081\n",
      "Epoch 175/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0976 - val_loss: 0.1082\n",
      "Epoch 176/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0975 - val_loss: 0.1082\n",
      "Epoch 177/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0974 - val_loss: 0.1082\n",
      "Epoch 178/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0979 - val_loss: 0.1084\n",
      "Epoch 179/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0986 - val_loss: 0.1081\n",
      "Epoch 180/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0975 - val_loss: 0.1081\n",
      "Epoch 181/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0970 - val_loss: 0.1081\n",
      "Epoch 182/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0967 - val_loss: 0.1081\n",
      "Epoch 183/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0966 - val_loss: 0.1081\n",
      "Epoch 184/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0965 - val_loss: 0.1081\n",
      "Epoch 185/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0964 - val_loss: 0.1081\n",
      "Epoch 186/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0964 - val_loss: 0.1081\n",
      "Epoch 187/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0964 - val_loss: 0.1082\n",
      "Epoch 188/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.1014 - val_loss: 0.1081\n",
      "Epoch 189/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0979 - val_loss: 0.1082\n",
      "Epoch 190/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0968 - val_loss: 0.1082\n",
      "Epoch 191/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0964 - val_loss: 0.1082\n",
      "Epoch 192/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0961 - val_loss: 0.1081\n",
      "Epoch 193/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0960 - val_loss: 0.1083\n",
      "Epoch 194/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0959 - val_loss: 0.1082\n",
      "Epoch 195/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0959 - val_loss: 0.1081\n",
      "Epoch 196/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0968 - val_loss: 0.1081\n",
      "Epoch 197/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0960 - val_loss: 0.1082\n",
      "Epoch 198/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0956 - val_loss: 0.1081\n",
      "Epoch 199/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0955 - val_loss: 0.1082\n",
      "Epoch 200/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0953 - val_loss: 0.1082\n",
      "Epoch 201/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0952 - val_loss: 0.1081\n",
      "Epoch 202/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0951 - val_loss: 0.1081\n",
      "Epoch 203/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0951 - val_loss: 0.1082\n",
      "Epoch 204/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0951 - val_loss: 0.1081\n",
      "Epoch 205/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0950 - val_loss: 0.1083\n",
      "Epoch 206/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0949 - val_loss: 0.1083\n",
      "Epoch 207/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0948 - val_loss: 0.1081\n",
      "Epoch 208/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0947 - val_loss: 0.1083\n",
      "Epoch 209/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0947 - val_loss: 0.1081\n",
      "Epoch 210/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0946 - val_loss: 0.1083\n",
      "Epoch 211/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0945 - val_loss: 0.1082\n",
      "Epoch 212/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0945 - val_loss: 0.1081\n",
      "Epoch 213/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0944 - val_loss: 0.1081\n",
      "Epoch 214/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0943 - val_loss: 0.1083\n",
      "Epoch 215/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0942 - val_loss: 0.1085\n",
      "Epoch 216/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0942 - val_loss: 0.1081\n",
      "Epoch 217/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0940 - val_loss: 0.1084\n",
      "Epoch 218/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0940 - val_loss: 0.1081\n",
      "Epoch 219/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0981 - val_loss: 0.1082\n",
      "Epoch 220/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0953 - val_loss: 0.1081\n",
      "Epoch 221/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0942 - val_loss: 0.1081\n",
      "Epoch 222/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0938 - val_loss: 0.1082\n",
      "Epoch 223/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0935 - val_loss: 0.1081\n",
      "Epoch 224/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0951 - val_loss: 0.1081\n",
      "Epoch 225/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0946 - val_loss: 0.1082\n",
      "Epoch 226/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0939 - val_loss: 0.1080\n",
      "Epoch 227/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0933 - val_loss: 0.1083\n",
      "Epoch 228/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0930 - val_loss: 0.1081\n",
      "Epoch 229/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0929 - val_loss: 0.1082\n",
      "Epoch 230/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0929 - val_loss: 0.1081\n",
      "Epoch 231/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0928 - val_loss: 0.1081\n",
      "Epoch 232/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0927 - val_loss: 0.1082\n",
      "Epoch 233/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0927 - val_loss: 0.1081\n",
      "Epoch 234/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0927 - val_loss: 0.1081\n",
      "Epoch 235/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0927 - val_loss: 0.1082\n",
      "Epoch 236/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0926 - val_loss: 0.1082\n",
      "Epoch 237/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0926 - val_loss: 0.1081\n",
      "Epoch 238/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0926 - val_loss: 0.1081\n",
      "Epoch 239/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0924 - val_loss: 0.1081\n",
      "Epoch 240/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0923 - val_loss: 0.1081\n",
      "Epoch 241/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0922 - val_loss: 0.1081\n",
      "Epoch 242/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0922 - val_loss: 0.1081\n",
      "Epoch 243/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0921 - val_loss: 0.1081\n",
      "Epoch 244/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0920 - val_loss: 0.1081\n",
      "Epoch 245/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0920 - val_loss: 0.1083\n",
      "Epoch 246/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0920 - val_loss: 0.1082\n",
      "Epoch 247/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0919 - val_loss: 0.1082\n",
      "Epoch 248/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0919 - val_loss: 0.1082\n",
      "Epoch 249/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0919 - val_loss: 0.1081\n",
      "Epoch 250/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0918 - val_loss: 0.1084\n",
      "Epoch 251/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0916 - val_loss: 0.1081\n",
      "Epoch 252/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0916 - val_loss: 0.1082\n",
      "Epoch 253/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0915 - val_loss: 0.1081\n",
      "Epoch 254/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0915 - val_loss: 0.1081\n",
      "Epoch 255/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0938 - val_loss: 0.1084\n",
      "Epoch 256/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0931 - val_loss: 0.1081\n",
      "Epoch 257/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0918 - val_loss: 0.1081\n",
      "Epoch 258/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0913 - val_loss: 0.1081\n",
      "Epoch 259/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0913 - val_loss: 0.1081\n",
      "Epoch 260/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0912 - val_loss: 0.1083\n",
      "Epoch 261/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0910 - val_loss: 0.1081\n",
      "Epoch 262/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0909 - val_loss: 0.1083\n",
      "Epoch 263/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0908 - val_loss: 0.1082\n",
      "Epoch 264/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0908 - val_loss: 0.1083\n",
      "Epoch 265/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0908 - val_loss: 0.1081\n",
      "Epoch 266/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0908 - val_loss: 0.1082\n",
      "Epoch 267/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0907 - val_loss: 0.1081\n",
      "Epoch 268/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0908 - val_loss: 0.1081\n",
      "Epoch 269/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0909 - val_loss: 0.1082\n",
      "Epoch 270/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0909 - val_loss: 0.1081\n",
      "Epoch 271/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0928 - val_loss: 0.1083\n",
      "Epoch 272/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0919 - val_loss: 0.1081\n",
      "Epoch 273/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0910 - val_loss: 0.1081\n",
      "Epoch 274/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0906 - val_loss: 0.1081\n",
      "Epoch 275/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0904 - val_loss: 0.1082\n",
      "Epoch 276/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0902 - val_loss: 0.1082\n",
      "Epoch 277/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0902 - val_loss: 0.1083\n",
      "Epoch 278/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0902 - val_loss: 0.1081\n",
      "Epoch 279/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0901 - val_loss: 0.1082\n",
      "Epoch 280/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1083\n",
      "Epoch 281/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1082\n",
      "Epoch 282/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1081\n",
      "Epoch 283/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0901 - val_loss: 0.1082\n",
      "Epoch 284/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0902 - val_loss: 0.1081\n",
      "Epoch 285/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1082\n",
      "Epoch 286/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1081\n",
      "Epoch 287/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0900 - val_loss: 0.1081\n",
      "Epoch 288/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0900 - val_loss: 0.1081\n",
      "Epoch 289/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0900 - val_loss: 0.1083\n",
      "Epoch 290/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0900 - val_loss: 0.1081\n",
      "Epoch 291/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0900 - val_loss: 0.1082\n",
      "Epoch 292/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0901 - val_loss: 0.1082\n",
      "Epoch 293/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0900 - val_loss: 0.1080\n",
      "Epoch 294/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0899 - val_loss: 0.1081\n",
      "Epoch 295/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0898 - val_loss: 0.1081\n",
      "Epoch 296/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0897 - val_loss: 0.1082\n",
      "Epoch 297/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0896 - val_loss: 0.1081\n",
      "Epoch 298/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0896 - val_loss: 0.1082\n",
      "Epoch 299/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0896 - val_loss: 0.1082\n",
      "Epoch 300/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0896 - val_loss: 0.1081\n",
      "Epoch 301/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0895 - val_loss: 0.1082\n",
      "Epoch 302/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0896 - val_loss: 0.1081\n",
      "Epoch 303/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0897 - val_loss: 0.1081\n",
      "Epoch 304/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0896 - val_loss: 0.1082\n",
      "Epoch 305/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0895 - val_loss: 0.1081\n",
      "Epoch 306/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0895 - val_loss: 0.1082\n",
      "Epoch 307/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0893 - val_loss: 0.1082\n",
      "Epoch 308/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0892 - val_loss: 0.1081\n",
      "Epoch 309/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0892 - val_loss: 0.1081\n",
      "Epoch 310/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0892 - val_loss: 0.1082\n",
      "Epoch 311/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0891 - val_loss: 0.1082\n",
      "Epoch 312/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0892 - val_loss: 0.1082\n",
      "Epoch 313/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0892 - val_loss: 0.1081\n",
      "Epoch 314/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0891 - val_loss: 0.1082\n",
      "Epoch 315/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0891 - val_loss: 0.1081\n",
      "Epoch 316/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0891 - val_loss: 0.1081\n",
      "Epoch 317/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0891 - val_loss: 0.1082\n",
      "Epoch 318/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0890 - val_loss: 0.1081\n",
      "Epoch 319/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0890 - val_loss: 0.1081\n",
      "Epoch 320/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0889 - val_loss: 0.1082\n",
      "Epoch 321/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0888 - val_loss: 0.1082\n",
      "Epoch 322/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0888 - val_loss: 0.1081\n",
      "Epoch 323/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0888 - val_loss: 0.1083\n",
      "Epoch 324/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0887 - val_loss: 0.1081\n",
      "Epoch 325/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0886 - val_loss: 0.1081\n",
      "Epoch 326/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0887 - val_loss: 0.1081\n",
      "Epoch 327/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0887 - val_loss: 0.1083\n",
      "Epoch 328/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0886 - val_loss: 0.1081\n",
      "Epoch 329/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0886 - val_loss: 0.1081\n",
      "Epoch 330/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0885 - val_loss: 0.1081\n",
      "Epoch 331/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0885 - val_loss: 0.1082\n",
      "Epoch 332/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0885 - val_loss: 0.1082\n",
      "Epoch 333/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0884 - val_loss: 0.1082\n",
      "Epoch 334/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0884 - val_loss: 0.1080\n",
      "Epoch 335/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0884 - val_loss: 0.1082\n",
      "Epoch 336/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0883 - val_loss: 0.1082\n",
      "Epoch 337/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0893 - val_loss: 0.1082\n",
      "Epoch 338/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0886 - val_loss: 0.1082\n",
      "Epoch 339/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0882 - val_loss: 0.1081\n",
      "Epoch 340/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0881 - val_loss: 0.1082\n",
      "Epoch 341/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0880 - val_loss: 0.1082\n",
      "Epoch 342/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1082\n",
      "Epoch 343/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0878 - val_loss: 0.1081\n",
      "Epoch 344/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1081\n",
      "Epoch 345/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1081\n",
      "Epoch 346/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1081\n",
      "Epoch 347/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1081\n",
      "Epoch 348/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0879 - val_loss: 0.1082\n",
      "Epoch 349/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0879 - val_loss: 0.1082\n",
      "Epoch 350/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0878 - val_loss: 0.1080\n",
      "Epoch 351/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0878 - val_loss: 0.1082\n",
      "Epoch 352/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0877 - val_loss: 0.1082\n",
      "Epoch 353/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0877 - val_loss: 0.1082\n",
      "Epoch 354/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0877 - val_loss: 0.1081\n",
      "Epoch 355/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0877 - val_loss: 0.1081\n",
      "Epoch 356/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0876 - val_loss: 0.1081\n",
      "Epoch 357/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0876 - val_loss: 0.1081\n",
      "Epoch 358/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0876 - val_loss: 0.1080\n",
      "Epoch 359/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0876 - val_loss: 0.1081\n",
      "Epoch 360/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0875 - val_loss: 0.1080\n",
      "Epoch 361/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0875 - val_loss: 0.1082\n",
      "Epoch 362/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0875 - val_loss: 0.1081\n",
      "Epoch 363/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0876 - val_loss: 0.1081\n",
      "Epoch 364/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0879 - val_loss: 0.1081\n",
      "Epoch 365/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0876 - val_loss: 0.1082\n",
      "Epoch 366/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0874 - val_loss: 0.1082\n",
      "Epoch 367/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0872 - val_loss: 0.1081\n",
      "Epoch 368/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0872 - val_loss: 0.1081\n",
      "Epoch 369/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0872 - val_loss: 0.1082\n",
      "Epoch 370/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0871 - val_loss: 0.1081\n",
      "Epoch 371/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0871 - val_loss: 0.1081\n",
      "Epoch 372/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0871 - val_loss: 0.1081\n",
      "Epoch 373/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0871 - val_loss: 0.1080\n",
      "Epoch 374/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0871 - val_loss: 0.1083\n",
      "Epoch 375/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0872 - val_loss: 0.1082\n",
      "Epoch 376/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0872 - val_loss: 0.1081\n",
      "Epoch 377/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0872 - val_loss: 0.1081\n",
      "Epoch 378/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0872 - val_loss: 0.1081\n",
      "Epoch 379/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0870 - val_loss: 0.1081\n",
      "Epoch 380/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0869 - val_loss: 0.1082\n",
      "Epoch 381/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0869 - val_loss: 0.1081\n",
      "Epoch 382/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0869 - val_loss: 0.1082\n",
      "Epoch 383/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0868 - val_loss: 0.1081\n",
      "Epoch 384/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0868 - val_loss: 0.1081\n",
      "Epoch 385/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0869 - val_loss: 0.1081\n",
      "Epoch 386/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0868 - val_loss: 0.1082\n",
      "Epoch 387/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0868 - val_loss: 0.1082\n",
      "Epoch 388/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0867 - val_loss: 0.1081\n",
      "Epoch 389/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0866 - val_loss: 0.1081\n",
      "Epoch 390/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0865 - val_loss: 0.1083\n",
      "Epoch 391/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0865 - val_loss: 0.1081\n",
      "Epoch 392/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0866 - val_loss: 0.1082\n",
      "Epoch 393/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0866 - val_loss: 0.1081\n",
      "Epoch 394/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0866 - val_loss: 0.1081\n",
      "Epoch 395/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0866 - val_loss: 0.1082\n",
      "Epoch 396/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0866 - val_loss: 0.1083\n",
      "Epoch 397/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0865 - val_loss: 0.1082\n",
      "Epoch 398/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0865 - val_loss: 0.1082\n",
      "Epoch 399/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0864 - val_loss: 0.1082\n",
      "Epoch 400/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0864 - val_loss: 0.1082\n",
      "Epoch 401/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0863 - val_loss: 0.1081\n",
      "Epoch 402/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0863 - val_loss: 0.1081\n",
      "Epoch 403/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0863 - val_loss: 0.1082\n",
      "Epoch 404/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0862 - val_loss: 0.1081\n",
      "Epoch 405/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0862 - val_loss: 0.1081\n",
      "Epoch 406/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0863 - val_loss: 0.1081\n",
      "Epoch 407/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0864 - val_loss: 0.1082\n",
      "Epoch 408/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0864 - val_loss: 0.1081\n",
      "Epoch 409/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0862 - val_loss: 0.1082\n",
      "Epoch 410/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0860 - val_loss: 0.1081\n",
      "Epoch 411/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0860 - val_loss: 0.1081\n",
      "Epoch 412/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0861 - val_loss: 0.1081\n",
      "Epoch 413/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0870 - val_loss: 0.1083\n",
      "Epoch 414/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0889 - val_loss: 0.1082\n",
      "Epoch 415/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0868 - val_loss: 0.1081\n",
      "Epoch 416/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0861 - val_loss: 0.1083\n",
      "Epoch 417/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0858 - val_loss: 0.1081\n",
      "Epoch 418/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0857 - val_loss: 0.1083\n",
      "Epoch 419/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 420/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1082\n",
      "Epoch 421/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 422/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 423/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0855 - val_loss: 0.1082\n",
      "Epoch 424/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 425/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 426/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 427/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 428/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 429/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0856 - val_loss: 0.1080\n",
      "Epoch 430/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0889 - val_loss: 0.1082\n",
      "Epoch 431/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0874 - val_loss: 0.1081\n",
      "Epoch 432/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0860 - val_loss: 0.1081\n",
      "Epoch 433/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0856 - val_loss: 0.1081\n",
      "Epoch 434/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0854 - val_loss: 0.1081\n",
      "Epoch 435/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 436/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1082\n",
      "Epoch 437/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 438/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 439/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1082\n",
      "Epoch 440/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 441/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 442/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 443/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 444/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 445/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 446/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 447/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1081\n",
      "Epoch 448/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1082\n",
      "Epoch 449/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 450/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 451/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 452/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 453/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 454/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1082\n",
      "Epoch 455/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0851 - val_loss: 0.1081\n",
      "Epoch 456/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0851 - val_loss: 0.1081\n",
      "Epoch 457/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0851 - val_loss: 0.1081\n",
      "Epoch 458/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0852 - val_loss: 0.1081\n",
      "Epoch 459/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0895 - val_loss: 0.1082\n",
      "Epoch 460/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0862 - val_loss: 0.1083\n",
      "Epoch 461/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0853 - val_loss: 0.1082\n",
      "Epoch 462/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0850 - val_loss: 0.1081\n",
      "Epoch 463/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1081\n",
      "Epoch 464/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1080\n",
      "Epoch 465/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 466/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 467/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 468/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 469/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 470/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1081\n",
      "Epoch 471/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1081\n",
      "Epoch 472/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1081\n",
      "Epoch 473/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 474/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 475/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 476/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 477/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 478/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1082\n",
      "Epoch 479/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 480/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 481/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 482/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1082\n",
      "Epoch 483/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 484/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1081\n",
      "Epoch 485/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 486/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1081\n",
      "Epoch 487/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 488/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 489/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 490/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 491/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 492/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1082\n",
      "Epoch 493/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1081\n",
      "Epoch 494/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 495/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 496/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 497/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 498/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 499/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 500/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1082\n",
      "Epoch 501/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1081\n",
      "Epoch 502/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0847 - val_loss: 0.1081\n",
      "Epoch 503/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0845 - val_loss: 0.1082\n",
      "Epoch 504/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0845 - val_loss: 0.1082\n",
      "Epoch 505/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0845 - val_loss: 0.1081\n",
      "Epoch 506/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0845 - val_loss: 0.1081\n",
      "Epoch 507/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0844 - val_loss: 0.1081\n",
      "Epoch 508/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0844 - val_loss: 0.1081\n",
      "Epoch 509/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0845 - val_loss: 0.1081\n",
      "Epoch 510/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0846 - val_loss: 0.1081\n",
      "Epoch 511/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0845 - val_loss: 0.1081\n",
      "Epoch 512/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0844 - val_loss: 0.1082\n",
      "Epoch 513/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0943 - val_loss: 0.1081\n",
      "Epoch 514/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0848 - val_loss: 0.1081\n",
      "Epoch 515/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0843 - val_loss: 0.1081\n",
      "Epoch 516/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 517/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 518/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1082\n",
      "Epoch 519/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 520/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 521/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 522/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 523/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 524/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 525/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1080\n",
      "Epoch 526/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0842 - val_loss: 0.1081\n",
      "Epoch 527/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 528/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1080\n",
      "Epoch 529/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1082\n",
      "Epoch 530/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 531/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 532/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1081\n",
      "Epoch 533/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1082\n",
      "Epoch 534/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 535/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0841 - val_loss: 0.1081\n",
      "Epoch 536/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1083\n",
      "Epoch 537/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0844 - val_loss: 0.1081\n",
      "Epoch 538/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0849 - val_loss: 0.1081\n",
      "Epoch 539/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0843 - val_loss: 0.1082\n",
      "Epoch 540/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1082\n",
      "Epoch 541/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 542/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 543/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 544/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 545/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 546/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1082\n",
      "Epoch 547/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 548/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 549/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1082\n",
      "Epoch 550/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 551/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 552/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0840 - val_loss: 0.1080\n",
      "Epoch 553/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 554/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 555/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 556/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1081\n",
      "Epoch 557/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 558/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 559/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1082\n",
      "Epoch 560/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 561/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1080\n",
      "Epoch 562/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 563/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0839 - val_loss: 0.1082\n",
      "Epoch 564/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 565/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 566/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 567/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 568/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1082\n",
      "Epoch 569/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 570/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 571/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 572/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1082\n",
      "Epoch 573/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0838 - val_loss: 0.1081\n",
      "Epoch 574/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 575/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 576/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 577/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 578/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1082\n",
      "Epoch 579/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 580/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 581/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 582/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 583/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 584/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 585/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1080\n",
      "Epoch 586/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1082\n",
      "Epoch 587/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0836 - val_loss: 0.1081\n",
      "Epoch 588/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1081\n",
      "Epoch 589/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0836 - val_loss: 0.1081\n",
      "Epoch 590/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1082\n",
      "Epoch 591/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0837 - val_loss: 0.1082\n",
      "Epoch 592/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0836 - val_loss: 0.1081\n",
      "Epoch 593/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0836 - val_loss: 0.1081\n",
      "Epoch 594/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0836 - val_loss: 0.1082\n",
      "Epoch 595/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0835 - val_loss: 0.1082\n",
      "Epoch 596/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0835 - val_loss: 0.1082\n",
      "Epoch 597/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0835 - val_loss: 0.1081\n",
      "Epoch 598/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0835 - val_loss: 0.1081\n",
      "Epoch 599/600\n",
      "187/187 [==============================] - 4s 22ms/step - loss: 0.0835 - val_loss: 0.1081\n",
      "Epoch 600/600\n",
      "187/187 [==============================] - 4s 21ms/step - loss: 0.0835 - val_loss: 0.1081\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(image_features,\n",
    "                    padded_embeddings,\n",
    "                    epochs=600, \n",
    "                    batch_size=32,\n",
    "                    validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40323fe-42ba-4e07-af53-4d453f6eb809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeff60d7-1e2e-4381-9e53-d966ecf7c7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in image embeddings: False\n",
      "NaNs in text embeddings: False\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "print(\"NaNs in image embeddings:\", np.isnan(image_features).any())\n",
    "print(\"NaNs in text embeddings:\", np.isnan(padded_embeddings).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746b1caf-2bbb-4ef6-8dd9-87a71436aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features[np.isnan(image_features)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a667c94e-b1ed-4358-9d16-9854ccdf612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in image embeddings: False\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in image embeddings:\", np.isnan(image_features).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e99ebac-72ba-48d4-9e07-fae6c7eb1ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract loss and validation loss from history\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Create a range object for the number of epochs\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c86e98-8721-49ae-8dce-02c32b31b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoha108/.local/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('ImgEmb-To-TextEmb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00983252-055c-4318-a6e3-c1baa57c739d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
